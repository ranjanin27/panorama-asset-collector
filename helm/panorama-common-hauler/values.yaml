# Default values for panorama-common-hauler.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 2

image:
  name: "panorama-common-hauler"
  repository: 740665670670.dkr.ecr.us-west-2.amazonaws.com/sc/panorama-common-hauler
  pullPolicy: Always

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: "vault-auth-panorama"

podAnnotations:
  prometheus.io/path: /metrics
  prometheus.io/port: "8300"
  prometheus.io/scrape: "true"
  proxy.istio.io/config: '{ "holdApplicationUntilProxyStarts": true }'

podSecurityContext:
  runAsUser: 10000
  runAsGroup: 10000

securityContext:
  capabilities:
    drop:
    - ALL
  runAsUser: 10000
  runAsGroup: 10000
  readOnlyRootFilesystem: true

service:
  type: ClusterIP
  restName: panorama-common-hauler-rest
  httpPort: 8300

env:
  # kafka related
  haulerConsumerKafkaTopic: panorama.common.hauler.collection
  haulerProducerKafkaTopic: panorama.hauler.collection.status
  haulerHarmonyKafkaTopic: panorama.common.hdpfilesync
  kafkaTlsMode: true
  kafkaTimeoutInSeconds: 10
  haulerKafkaGroupId: panorama.common.hauler.consumergroup

  debugMode: true
  deployMode: prod # TODO: Change to prod
  logLevel: info

  # Env variables for connecting to authz service
  authzEndpoint: "grpc.authz.svc.cluster.local:5100"
  authzDisable: false

  # AWS related
  awsAccessKeyId: ""
  awsSecretAccessKey: ""
  # Env variables for connecting to Fleet service
  fleetGrpcEndpoint: "fleet-grpc-api-service.fleet.svc.cluster.local:5565"
  fleetGrpcDeviceType1Endpoint: "fleet-grpc-api-device-type1-service.fleet.svc.cluster.local:5565"
  fleetGrpcDeviceType2Endpoint: "fleet-grpc-api-device-type2-service.fleet.svc.cluster.local:5565"
  fleetNbRestURL: "fleet-nb-rest.fleet.svc.cluster.local:3443"
  # Env variable whether we use CustomerID in GET Call or not
  useCustomerID: true
  updateServiceAuthExpiryTimeoutMins: 120
  isLocal: false
  localCluster: false
  pprofEnabled: false
  sourceType: "Common"
  fileDomain: "panorama"
  retryBackoff: "3s"
  restConnectionTimeout: 60

healthCheck:
    livenessProbe:
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
    readinessProbe:
      initialDelaySeconds: 30
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths: []
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources:
  limits:
    cpu: 200m
    memory: 2Gi
  requests:
    cpu: 50m
    memory: 512Mi
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 8
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []
